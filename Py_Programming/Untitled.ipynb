{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204606d6-dc84-4bf5-9819-464e4c41f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import numpy as np\n",
    "import doubleml as dml\n",
    "from doubleml.datasets import make_heterogeneous_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ff7165cd-ed7e-4613-bb87-e312e0d3eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_feature = RBFSampler(gamma=1.0, n_components=100, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cfff79-72f6-4f8a-a7db-c60e2123a583",
   "metadata": {},
   "source": [
    ".fit_transform(X) transforms each example into random basis representations.\n",
    "\n",
    "The resulting matrix is $n \\times w$, where $n$ is the number of obs and $w$ is the number of random basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d76ce551-83aa-4601-8dce-1064df624775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index(['y', 'd', 'X_0', 'X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8',\n",
      "       'X_9'],\n",
      "      dtype='object')\n",
      "          y    d       X_0       X_1       X_2       X_3       X_4       X_5  \\\n",
      "0  4.803300  1.0  0.259828  0.886086  0.895690  0.297287  0.229994  0.411304   \n",
      "1  5.655547  1.0  0.824350  0.396992  0.156317  0.737951  0.360475  0.671271   \n",
      "2  1.878402  0.0  0.988421  0.977280  0.793818  0.659423  0.577807  0.866102   \n",
      "3  6.941440  1.0  0.427486  0.330285  0.564232  0.850575  0.201528  0.934433   \n",
      "4  1.703049  1.0  0.016200  0.818380  0.040139  0.889913  0.991963  0.294067   \n",
      "\n",
      "        X_6       X_7       X_8       X_9  \n",
      "0  0.240532  0.672384  0.826065  0.673092  \n",
      "1  0.270644  0.081230  0.992582  0.156202  \n",
      "2  0.289440  0.467681  0.619390  0.411190  \n",
      "3  0.689088  0.823273  0.556191  0.779517  \n",
      "4  0.210319  0.765363  0.253026  0.865562  \n",
      "<class 'numpy.ndarray'>\n",
      "(2000, 10)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "data_dict = make_heterogeneous_data(\n",
    "    n_obs=2000,\n",
    "    p=10,\n",
    "    support_size=5,\n",
    "    n_x=1,\n",
    "    binary_treatment=True,\n",
    ")\n",
    "treatment_effect = data_dict['treatment_effect']\n",
    "data = data_dict['data']\n",
    "print(type(data))\n",
    "print(data.columns)\n",
    "print(data.head())\n",
    "\n",
    "X = data.filter(like='X').to_numpy()\n",
    "Y = data.filter(like='y').to_numpy()\n",
    "print(type(X))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2f542f8e-0cf6-48e1-be4f-d4e91696b39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4119220370753744"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t = data[data['d'] == 1]\n",
    "Y_t  = df_t.filter(like='y').to_numpy()\n",
    "X_t  = df_t.filter(like='X').to_numpy()\n",
    "X_t_transform = rbf_feature.fit_transform(X_t)\n",
    "krr_t = KernelRidge(alpha=1e-5)\n",
    "krr_t.fit(X_t_transform, Y_t)\n",
    "\n",
    "\n",
    "df_c = data[data['d'] == 0]\n",
    "Y_c  = df_c.filter(like='y').to_numpy()\n",
    "X_c  = df_cfrom scipy.stats.qmc import Sobol\n",
    "\n",
    "M = 2048\n",
    "p = 10   # number of covariates\n",
    "sobol_points = Sobol(d=p, scramble=False).random(M)\n",
    ".filter(like='X').to_numpy()\n",
    "X_c_transform = rbf_feature.fit_transform(X_c)\n",
    "krr_c = KernelRidge(alpha=1e-5)\n",
    "krr_c.fit(X_c_transform, Y_c)\n",
    "\n",
    "\n",
    "from scipy.stats.qmc import Sobol\n",
    "M = 2048\n",
    "sobol_points = Sobol(d=X.shape[1]).random(M)\n",
    "# Map Sobol points into RFF feature space\n",
    "Z_sobol = rbf_feature.transform(sobol_points)\n",
    "\n",
    "np.mean(np.maximum(0, krr_t.predict(Z_sobol) - krr_c.predict(Z_sobol)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "59020f7b-02e6-4914-93d7-40af63ababeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True optimal welfare: 4.449629628029234\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats.qmc import Sobol\n",
    "\n",
    "# Step 1: reconstruct CATE function\n",
    "def true_tau(x):\n",
    "    return np.exp(2 * x[:, 0]) + 3 * np.sin(4 * x[:, 1])\n",
    "\n",
    "# Step 2: Sobol points\n",
    "p = X.shape[1]\n",
    "M = 2048\n",
    "sobol_points = Sobol(d=p).random(M)\n",
    "\n",
    "# Step 3: evaluate tau\n",
    "tau_sobol = true_tau(sobol_points)\n",
    "\n",
    "# Step 4: ReLU + average\n",
    "W_true = np.mean(np.maximum(0, tau_sobol))\n",
    "print(\"True optimal welfare:\", W_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e4a3bbb-b583-4b44-a3de-468b702ab34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True optimal welfare = 4.447681288540517\n",
      "Completed: 50\n",
      "Completed: 100\n",
      "Completed: 150\n",
      "Completed: 200\n",
      "Completed: 250\n",
      "Completed: 300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 100\u001b[0m\n\u001b[1;32m     97\u001b[0m results \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(rep)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rep):\n\u001b[0;32m--> 100\u001b[0m     results[r] \u001b[38;5;241m=\u001b[39m compute_optimal_welfare()\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (r\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted:\u001b[39m\u001b[38;5;124m\"\u001b[39m, r\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 69\u001b[0m, in \u001b[0;36mcompute_optimal_welfare\u001b[0;34m(n_obs, p, support_size, gamma, alpha, sobol_points, n_components)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# ----------------- linear ridge = approx KRR ---\u001b[39;00m\n\u001b[1;32m     68\u001b[0m krr_t \u001b[38;5;241m=\u001b[39m KernelRidge(alpha\u001b[38;5;241m=\u001b[39malpha, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(B_t, Y_t)\n\u001b[0;32m---> 69\u001b[0m krr_c \u001b[38;5;241m=\u001b[39m KernelRidge(alpha\u001b[38;5;241m=\u001b[39malpha, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(B_c, Y_c)\n\u001b[1;32m     71\u001b[0m e_t \u001b[38;5;241m=\u001b[39m Y_t \u001b[38;5;241m-\u001b[39m krr_t\u001b[38;5;241m.\u001b[39mpredict(B_t)\n\u001b[1;32m     72\u001b[0m e_c \u001b[38;5;241m=\u001b[39m Y_c \u001b[38;5;241m-\u001b[39m krr_c\u001b[38;5;241m.\u001b[39mpredict(B_c)     \u001b[38;5;66;03m# FIXED\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1468\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m-> 1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[1;32m   1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/contextlib.py:141\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, typ, value, traceback):\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats.qmc import Sobol\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from doubleml.datasets import make_heterogeneous_data\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# ---------------------------\n",
    "# SIMULATION PARAMETERS\n",
    "# ---------------------------\n",
    "rep = 500\n",
    "M = 1024\n",
    "p = 2\n",
    "n = 1500\n",
    "support_size = 2\n",
    "gamma = 1.0\n",
    "alpha = 1e-5\n",
    "n_components = 100\n",
    "\n",
    "# ---------------------------\n",
    "# TRUE CATE FUNCTION\n",
    "# ---------------------------\n",
    "def true_tau(x):\n",
    "    return np.exp(2 * x[:, 0]) + 3 * np.sin(4 * x[:, 1])\n",
    "\n",
    "# Sobol grid\n",
    "sobol_points = Sobol(d=p, scramble=False).random(M)\n",
    "tau_sobol = true_tau(sobol_points)\n",
    "W_true = np.mean(np.maximum(0, tau_sobol))\n",
    "print(\"True optimal welfare =\", W_true)\n",
    "\n",
    "# ---------------------------\n",
    "# ONE ITERATION\n",
    "# ---------------------------\n",
    "def compute_optimal_welfare(n_obs=n, p=p, support_size=support_size,\n",
    "                            gamma=gamma, alpha=alpha,\n",
    "                            sobol_points=sobol_points,\n",
    "                            n_components=n_components):\n",
    "    \n",
    "    data_dict = make_heterogeneous_data(\n",
    "        n_obs=n_obs,\n",
    "        p=p,\n",
    "        support_size=support_size,\n",
    "        n_x=1,\n",
    "        binary_treatment=True,\n",
    "    )\n",
    "    data = data_dict[\"data\"]\n",
    "\n",
    "    # -------------------- split --------------------\n",
    "    df_t = data[data[\"d\"] == 1]\n",
    "    df_c = data[data[\"d\"] == 0]\n",
    "\n",
    "    Y_t = df_t[\"y\"].to_numpy().ravel()\n",
    "    X_t = df_t.filter(like=\"X\").to_numpy()\n",
    "\n",
    "    Y_c = df_c[\"y\"].to_numpy().ravel()\n",
    "    X_c = df_c.filter(like=\"X\").to_numpy()\n",
    "\n",
    "    # ----------------- RFF -------------------------\n",
    "    rff = RBFSampler(gamma=gamma, n_components=n_components, random_state=42)\n",
    "\n",
    "    B_all = rff.fit_transform(np.vstack([X_t, X_c]))\n",
    "    B_t = B_all[: len(X_t)]\n",
    "    B_c = B_all[len(X_t) :]\n",
    "\n",
    "    # ----------------- linear ridge = approx KRR ---\n",
    "    krr_t = KernelRidge(alpha=alpha, kernel=\"linear\").fit(B_t, Y_t)\n",
    "    krr_c = KernelRidge(alpha=alpha, kernel=\"linear\").fit(B_c, Y_c)\n",
    "\n",
    "    e_t = Y_t - krr_t.predict(B_t)\n",
    "    e_c = Y_c - krr_c.predict(B_c)     # FIXED\n",
    "\n",
    "    # ---------------- Sobol evaluation ---------------\n",
    "    B_int = rff.transform(sobol_points)\n",
    "    h_int = krr_t.predict(B_int) - krr_c.predict(B_int)\n",
    "\n",
    "    W_hat = np.mean(np.maximum(0, h_int))\n",
    "\n",
    "    # -------------- Asymptotic Variance --------------\n",
    "    ind_good = (h_int >= 0)\n",
    "    bases    = np.hstack([B_int, -B_int])\n",
    "    Bun      = bases[ind_good, :].sum(axis=0) / len(bases)\n",
    "    Bun_t    = Bun[:B_int.shape[1]]\n",
    "    Bun_c    = Bun[B_int.shape[1]:]\n",
    "    \n",
    "    R_t = np.linalg.inv(B_t.T @ B_t + alpha * np.eye(B_t.shape[1])) # R matrix: (B'B + λI)^(-1)\n",
    "    R_c = np.linalg.inv(B_c.T @ B_c + alpha * np.eye(B_c.shape[1])) \n",
    "\n",
    "    Patty_t = R_t @ (B_t.T @  np.diag(e_t**2) @ B_t) @ R_t\n",
    "    Patty_c = R_c @ (B_c.T @  np.diag(e_c**2) @ B_c) @ R_c\n",
    "\n",
    "    asy_var = float(Patty_t + Patty_c)\n",
    "    se      = np.sqrt(asy_var)\n",
    "    \n",
    "    return W_hat, se\n",
    "\n",
    "# ---------------------------\n",
    "# MONTE CARLO LOOP\n",
    "# ---------------------------\n",
    "results = np.zeros(rep)\n",
    "\n",
    "for r in range(rep):\n",
    "    results[r] = compute_optimal_welfare()\n",
    "    if (r+1) % 50 == 0:\n",
    "        print(\"Completed:\", r+1)\n",
    "\n",
    "print(\"\\nMC mean =\", results.mean())\n",
    "print(\"Bias (mean - W_true) =\", results.mean() - W_true)\n",
    "print(\"Std =\", results.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4345d40-4407-4ca3-af35-b589f992a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Asymptotic variance ---\n",
    "    # ind_good = (h0_B_int >= 0)\n",
    "\n",
    "    # term3 = np.hstack([B_int, -B_int])\n",
    "    # Bun = term3[ind_good, :].sum(axis=0) / len(term3)\n",
    "    # Bun_t = Bun[:B_int.shape[1]]\n",
    "    # Bun_c = Bun[B_int.shape[1]:]\n",
    "\n",
    "    # R_t = np.linalg.inv(B_t.T @ B_t + alpha * np.eye(B_t.shape[1])) # R matrix: (B'B + λI)^(-1)\n",
    "    # R_c = np.linalg.inv(B_c.T @ B_c + alpha * np.eye(B_c.shape[1])) # R matrix: (B'B + λI)^(-1)\n",
    "    \n",
    "\n",
    "    # Patty_t = R_t @ (B_t.T @  np.diag(e_t**2) @ B_t) @ R_t\n",
    "    # Patty_c = R_c @ (B_c.T @  np.diag(e_c**2) @ B_c) @ R_c\n",
    "\n",
    "    #asy_var = float(Bun_t @ Patty_t @ Bun_t + Bun_c @ Patty_c @ Bun_c)\n",
    "    #se = np.sqrt(asy_var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
